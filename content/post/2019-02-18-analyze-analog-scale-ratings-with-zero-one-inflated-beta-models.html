---
title: How to analyze visual analog (slider) scale data?
author: Matti Vuorre
date: '2019-02-18'
slug: analyze-analog-scale-ratings-with-zero-one-inflated-beta-models
categories:
  - psychology
  - statistics
tags:
  - bayes
  - brms
  - data visualization
  - modeling
  - psychology
  - R
  - research methods
  - statistics
  - tutorial
image:
  caption: ''
  focal_point: ''
subtitle: 'A reasonable choice might be the zero-one-inflated beta model'
output:
  blogdown::html_page:
    toc: yes
    number_sections: no
    toc_depth: 1
    df_print: paged
summary: 'Ratings provided on visual analog scales (VAS), or slider scales, are unlikely to be normally distributed. Nevertheless, researchers typically use the normal distribution to analyze analog scale ratings, such as when they perform ANOVAs, t-tests, and correlations. A potentially better model of analog ratings, which are typically skewed and have lower and upper limits, is the so called zero-one-inflated beta model. In this post, I explain this model, illustrate its use with simulated and data, and compare its performance to t-tests in comparing two groups slider ratings.'
bibliography: "../../references.bib"
---

<link href="/rmarkdown-libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
<script src="/rmarkdown-libs/pagedtable/js/pagedtable.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-zero-one-inflated-beta-model">The zero-one-inflated beta model</a></li>
<li><a href="#zoib-regression">ZOIB regression</a></li>
<li><a href="#simulation-compare-zoib-and-t-test-performances">Simulation: Compare ZOIB and t-test performances</a></li>
<li><a href="#discussion">Discussion</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In psychological experiments, subjective responses are often collected using two types of response scales: ordinal and visual analog scales. These scales are unlikely to provide normally distributed data. However, researchers often analyze responses from these scales with models that assume normality of the data.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>Ordinal scales, of which binary ratings are a special case, provide ordinal data and are thus better analyzed using ordinal models <span class="citation">(Bürkner and Vuorre 2018; Liddell and Kruschke 2018)</span>.</p>
<p>Analog scales, also known as slider scales, are also unlikely to provide normally distributed responses because the scale is bounded at the low and high ends. These responses also tend to be skewed. It is common for slider responses to bunch at either end of the slider scale, potentially making the deviation from normality more severe.</p>
<p>For example, Figure <a href="#fig:vas-example-image">1</a> shows a slider scale in action. (I found this random example with a simple internet search at <a href="https://blog.surveyhero.com/2018/09/03/new-question-type-slider/" class="uri">https://blog.surveyhero.com/2018/09/03/new-question-type-slider/</a>). In experiments using slider scales, subjects are typically instructed to use their mouse to drag a response indicator along a horizontal line, and/or click with a mouse on a point of the scale that matches their subjective impression. Sometimes these responses are provided on paper, where subjects are asked to bisect a line at a point that matches their subjective feeling (e.g. halfway between “Leisure” and “Money” if they are subjectively equally important.)</p>
<div class="figure"><span id="fig:vas-example-image"></span>
<img src="/img/vas.gif" alt="Example slider scale from https://blog.surveyhero.com/2018/09/03/new-question-type-slider/"  />
<p class="caption">
Figure 1: Example slider scale from <a href="https://blog.surveyhero.com/2018/09/03/new-question-type-slider/" class="uri">https://blog.surveyhero.com/2018/09/03/new-question-type-slider/</a>
</p>
</div>
<p>These analog ratings are sometimes thought to be ‘better’ than discrete ordinal ratings (Likert item responses) because of the greater resolution of the slider scale. The scale’s resolution is limited only by the resolution of the monitor: For example, if the rating scale is 100 pixels wide, there are 100 possible values for the ratings. It is not unthinkable that such ratings can be considered continuous between the low and high endpoints. However, they are often not well described by the normal distribution.</p>
<div id="normal-model-of-slider-ratings" class="section level2">
<h2>Normal model of slider ratings</h2>
<p>Consider Figure <a href="#fig:simulate-example">2</a>. This figure shows 200 simulated ratings on a [0, 1] slider scale (meaning that any value between 0 and 1, inclusive of the endpoints, is possible). I have also superimposed a blue curve of the best-fitting normal density on the histogram. The two most notable non-normal features of these data are that they are bounded at 0 and 1 where the data appears to “bunch”, and (possibly) skewed. Of course, these data were simulated; experience with slider scales tells me, however, that this histogram is not unrepresentative of such ratings.</p>
<div class="figure"><span id="fig:simulate-example"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/simulate-example-1.png" alt="Histogram of 200 simulated slider scale ratings,  with a superimposed best-fitting density curve from a normal distribution." width="480" />
<p class="caption">
Figure 2: Histogram of 200 simulated slider scale ratings, with a superimposed best-fitting density curve from a normal distribution.
</p>
</div>
<p>While the height of the blue curve is not comparable to the heights of the bars (one represents a density, the other counts of observations in rating bins), it should be apparent that features of the rating scale data make the blue normal curve a poor representation of the data.</p>
<p>First, the skew apparent in the data is not captured by the normal density curve. Second, and perhaps more important, the blue curve does not respect the 0 and 1 boundaries of the slider scale data.</p>
<p>Focus on this latter point: We can see that the blue curve assigns density to areas outside the possible values: The model predicts impossible values with alarming frequency. Second, the boundary values 0.0 and 1.0 do not receive any special treatment under the normal model, but we can see that the data are bunched at the boundaries. The great frequency of responses at 0.0 and 1.0 leads to large prediction errors from the normal model of these data.</p>
<p>In other words, (simulated) subjects tend to give many extreme ratings. This is especially apparent in the low end of the rating scale, where the continuous spread of scores tapers off, but then there is a large spike of ratings at zero. The normal model misses these features of the data, and may therefore lead to unrepresentative estimates of the data generating process, and even erroneous conclusions.</p>
</div>
<div id="toward-a-better-model" class="section level2">
<h2>Toward a better model</h2>
<p>More generally, if your goal is to predict cognition and behavior <span class="citation">(Yarkoni and Westfall 2017)</span>, a model that is obviously a poor representation of your data—in terms of having such a poor predictive utility—should not be your first choice for data analysis.</p>
<p>Admittedly, the data in Figure <a href="#fig:simulate-example">2</a> were simulated, and it remains an empirical question as to how common these features are in real data, and how severe these issues are to normal models (t-test, ANOVA, correlation, etc.).</p>
<p>Nevertheless, it would be desirable to have an accessible data-analytic model for slider scale data, whose assumption better match observed features of the data. Here, I introduce one such model—the zero-one-inflated beta (ZOIB) model—and show how it can be applied to real data using the R package brms <span class="citation">(Bürkner 2017)</span>. I also compare this model to standard analyses of slider scale data and conclude that the ZOIB can provide more detailed and accurate inferences from data than its conventional counterparts.</p>
<div class="figure"><span id="fig:meme"></span>
<img src="/img/zoidberg.jpg" alt="Dr. John A. Zoidberg thinks you should try a ZOIB model on your slider scale data."  />
<p class="caption">
Figure 3: Dr. John A. Zoidberg thinks you should try a ZOIB model on your slider scale data.
</p>
</div>
</div>
</div>
<div id="the-zero-one-inflated-beta-model" class="section level1">
<h1>The zero-one-inflated beta model</h1>
<p>Above, we established—rather informally—that normal models may be less than optimal for slider scale data. Of course, no model is the <em>correct</em> model of such data, but it would be desirable to use a model that best represents the data under study.</p>
<p>The model for analysis of slider scale data discussed here has been called the “zero-one-inflated beta” model, or ZOIB <span class="citation">(Liu and Kong 2015)</span>. It is a model of data in the closed [0, 1] interval, and has two components: A beta distribution for responses in the closed (0, 1) interval, and a bernoulli distribution for the binary {0, 1} responses. Under this model, predictors can affect either or both the continuous and binary responses, the proportion of binary responses, or the spread of the continuous ratings.</p>
<p>To understand ZOIB, let’s start with a closer look at the theoretical beta density.</p>
<div id="the-beta-distribution" class="section level2">
<h2>The beta distribution</h2>
<p>The beta distribution used in beta regression <span class="citation">(Ferrari and Cribari-Neto 2004)</span> is a model of data in the open (0, 1) interval. (i.e. all values from 0 to 1, but not 0 and 1 themselves, are permitted.)</p>
<p>The beta distribution typically has two parameters, which in R are called <code>shape1</code> and <code>shape2</code>. Together, they determine the location, spread, and skew of the distribution. Four example beta densities are shown in Figure <a href="#fig:beta-distributions">4</a>. Using R’s <code>dbeta()</code>, I drew four curves corresponding to beta densities with different <code>shape1</code> and <code>2</code> parameters.</p>
<div class="figure"><span id="fig:beta-distributions"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/beta-distributions-1.png" alt="Four examples of the beta density, corresponding to different shape parameters." width="672" />
<p class="caption">
Figure 4: Four examples of the beta density, corresponding to different shape parameters.
</p>
</div>
<p>This default parameterization is useful, for example, as a prior distribution for proportions: The <code>shape1</code> and <code>shape2</code> parameters can define the prior number of zeros and ones, respectively. For example, in the above figure, <code>dbeta(x, shape1 = 1, shape2 = 1)</code> results in a uniform prior over proportions, because the prior zeros and ones are 1 each.</p>
<p>However, for our purposes, it is more useful to parameterize the beta distribution with a mean and a precision. To convert the former parameterization to mean (which we’ll call <span class="math inline">\(\mu\)</span> (mu)) and precision (<span class="math inline">\(\phi\)</span> (phi)), the following formulas can be used</p>
<p><span class="math inline">\(\mbox{shape1} = \mu \phi \\ \mbox{shape2} = (1 - \mu)\phi\)</span></p>
<p>(This parameterization is provided in R in the PropBeta functions from the extraDist package, which calls the precision parameter, or <span class="math inline">\(\phi\)</span>, <code>size</code>.) Redrawing the figure from above with this parameterization using the <code>dprop()</code> function, we get Figure <a href="#fig:beta-reparameterized-distributions">5</a>.</p>
<div class="figure"><span id="fig:beta-reparameterized-distributions"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/beta-reparameterized-distributions-1.png" alt="Four examples of the reparameterized beta density (`dprop()`)." width="672" />
<p class="caption">
Figure 5: Four examples of the reparameterized beta density (<code>dprop()</code>).
</p>
</div>
<p>Shown above are four density functions of the beta family, whose precision and mean are varied. The first (red line) is a beta distribution with precision = 1, and mean = 0.5. It results in a uniform distribution. If a subject gave random slider scale responses, they might look much like this distribution (any rating is equally probably as any other rating).</p>
<p>The second beta distribution (green line) has precision 10, and mean 0.2. It is heavily skewed to the right. The third distribution (teal line) has precision 10, and a mean of 0.9. The fourth one, most similar to a normal distribution, has precision 70 and mean 0.50 (purple line).</p>
<p>In beta regression, this family of distributions is used to model observations, and covariates can have effects on both the mean and precision parameters.</p>
<p>However, beta regression only allows outcomes in the open (0, 1) interval. We know that slider scales often result in a bunching of values at the boundaries, and these boundary values might be informative of the participants’ cognition and behavior. To handle these extreme values, we can add a zero-one inflation process to the beta distribution.</p>
</div>
<div id="zero-one-inflation" class="section level2">
<h2>Zero-one inflation</h2>
<p>The zero-one-inflated beta (ZOIB) adds a separate discrete process for the {0, 1} values, using two additional parameters. Following convention, we shall call them <span class="math inline">\(\alpha\)</span> (alpha) and <span class="math inline">\(\gamma\)</span> (gamma). These parameters describe the probability of an observation being a 0 or 1 (<span class="math inline">\(\alpha\)</span>), and conditional on that, whether the observation was 1 (<span class="math inline">\(\gamma\)</span>).</p>
<p>In other words, the model of outcomes under ZOIB is described by four parameters. The first is <span class="math inline">\(\alpha\)</span>, the probability that an observation is either 0 or 1. (Thus, <span class="math inline">\(1-\alpha\)</span> is the probability of a non-boundary observation.) If an observation is not 0 or 1, the datum is described by the beta distribution with some mean <span class="math inline">\(\mu\)</span> and precision <span class="math inline">\(\phi\)</span>. If an observation is 0 or 1, the probability of it being 1 is given by <span class="math inline">\(\gamma\)</span> (just like your usual model of binary outcomes, e.g. logistic regression). So you can think of the model as a kind of mixture of beta and logistic regressions, where the <span class="math inline">\(\alpha\)</span> parameter describes the mixing proportions. The mathematical representation of this model is given in <a href="https://cran.rstudio.com/web/packages/brms/vignettes/brms_families.html#zero-inflated-and-hurdle-models">this vignette</a> <span class="citation">(Bürkner 2017)</span>.</p>
<p>To illustrate, I wrote a little function <code>rzoib()</code> that takes these parameters as arguments, and generates <code>n</code> random draws. Here is a histogram of 1k samples from four ZOIB distributions with various combinations of the parameters:</p>
<div class="figure"><span id="fig:zoib-distributions"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/zoib-distributions-1.png" alt="Four different ZOIB distributions resulting from various combinations of the parameters. (Parameter names are abbreviated; a = alpha, g = gamma, etc.)" width="672" />
<p class="caption">
Figure 6: Four different ZOIB distributions resulting from various combinations of the parameters. (Parameter names are abbreviated; a = alpha, g = gamma, etc.)
</p>
</div>
<p>Take the first (red) one. <span class="math inline">\(\alpha\)</span> was set to zero, and therefore there are no observations exactly at zero or 1. Because <span class="math inline">\(\alpha = 0\)</span>, it doesn’t matter that <span class="math inline">\(\gamma\)</span> was set to 0.5. <span class="math inline">\(\gamma\)</span> is the conditional one probability, given that the observation was 0 or 1. Therefore, the first histogram only contains draws from a beta distribution with mean = 0.2, and precision = 6.</p>
<p>Next, take a look at the second (green) histogram. Here, <span class="math inline">\(\alpha = 0.1\)</span>, so 10% of the observations will be either 0 or 1. Of these 10%, 30% are ones (<span class="math inline">\(\gamma = 0.3\)</span>). The bulk of the distribution, 90%, are draws from a beta distribution with a mean = 0.5, and precision = 3.</p>
<p>The bottom two histograms are two more combinations of the four parameters. Try to understand how their shapes are explained by the specific parameter combinations.</p>
<p>In summary, ZOIB is a reasonable model of slider scale data that can capture their major features, has support for the entire [0, 1] range of data, and does not assign density to impossible values (unlike the normal model). It also has an intuitive way of dealing with the boundary values as a separate process, thus providing more nuanced information about the outcome variable under study.</p>
<p>Next, we discuss a regression model with ZOIB as the data model: We are most interested in how other variables affect or relate to the outcome variables under study (slider scale ratings). By modeling the four parameters of the ZOIB model on predictors, ZOIB regression allows us to do just that.</p>
</div>
</div>
<div id="zoib-regression" class="section level1">
<h1>ZOIB regression</h1>
<p>In this example, we examine the ZOIB model in the context of one binary predictor variable (Group A vs B, a “between subjects” manipulation).</p>
<div id="example-data" class="section level2">
<h2>Example data</h2>
<p>To illustrate the ZOIB model in action, I simulated a data set of 100 ratings from two groups, A and B. These data are shown in Figure <a href="#fig:zoib-example">7</a>.</p>
<div class="figure"><span id="fig:zoib-example"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/zoib-example-1.png" alt="Simulated data set of two group's slider scale ratings, with means and bootstrapped 95\% CIs in blue. The ratings are jittered horizontally to reveal overlapping data points." width="288" />
<p class="caption">
Figure 7: Simulated data set of two group’s slider scale ratings, with means and bootstrapped 95% CIs in blue. The ratings are jittered horizontally to reveal overlapping data points.
</p>
</div>
<p>We are interested in the extent to which Group A’s ratings differ from Group B’s ratings. It is common practice to address this question with a t-test, treating the ratings as normally distributed within each group. I compared the two groups’ means with a t-test: The difference was not statistically significant (B - A = 0.06, 95%CI = [-0.07, 0.2], p=0.340). I’ve also heard that you can do something called a Mann-Whitney U test, or a Kruskal-Wallis test when you have a categorical predictor and don’t want to assume a parametric form for your outcomes. I tried those as well. Neither of these nonparametric tests were significant (p=0.226; p=0.225). I therefore concluded that I was unable to reject the null hypothesis that Group A and Group B’s population means are not different.</p>
<p>But as can be seen from Figure <a href="#fig:simulate-example">2</a>, the normal model makes unreasonable assumptions about these ratings. We see in Figure <a href="#fig:zoib-example">7</a> that there are many non-normal features in this example data set; e.g. many values are bunched at 0.0 and 1.0. Let’s fit the ZOIB model on these data, and see if our conclusions differ. Spoiler alert: they do.</p>
</div>
<div id="the-model" class="section level2">
<h2>The model</h2>
<p>We will model the data as ZOIB, and use <code>group</code> as a predictor of the mean and precision of the beta distribution, the zero-one inflation probability <span class="math inline">\(\alpha\)</span>, and the conditional one-inflation probability <span class="math inline">\(\gamma\)</span>. In other words, in this model <code>group</code> may affect the mean and/or precision of the assumed beta distribution of the continuous ratings (0, 1), and/or the probability with which a binary rating is given, and/or the probability that a binary rating is 1. How do we estimate this model?</p>
<p>It might not come as a surprise that we estimate the model with bayesian methods, using the R package brms <span class="citation">(Bürkner 2017)</span>. Previously, I have discussed how to estimate signal detection theoretic models, “robust models”, and other multilevel models using this package. I’m a big fan of brms because of its modeling flexibility and post-processing functions: With concise syntax, you can fit a wide variety of possibly nonlinear, multivariate, and multilevel models, and analyze and visualize the models’ results.</p>
<p>Let’s load the package, and start building our model.</p>
<pre class="r"><code>library(brms)</code></pre>
<p>The R formula syntax allows a concise representation of regression models in the form of <code>response ~ predictors</code>. For a simple normal (i.e. gaussian) model of the mean of <code>Ratings</code> as a function of <code>group</code>, you could write <code>Ratings ~ group, family = gaussian</code>. However, we want to predict the four parameters of the ZOIB model, and so will need to expand this notation.</p>
<p>The brms package allows modeling more than one parameter of an outcome distribution. Specifically, we want to predict so-called “distributional parameters”, and <code>bf()</code> allows predicting them in their own formulas. Implicitly, <code>Ratings ~ group</code> means that you want to model the <em>mean</em> of <code>Ratings</code> on <code>group</code>. Therefore, to model <span class="math inline">\(\phi\)</span>, <span class="math inline">\(\alpha\)</span>, and <span class="math inline">\(\gamma\)</span>, we will give them their own regression formulas within a call to <code>bf()</code>:</p>
<pre class="r"><code>zoib_model &lt;- bf(
  Rating ~ group,
  phi ~ group,
  zoi ~ group,
  coi ~ group, 
  family = zero_one_inflated_beta()
)</code></pre>
<p>The four sub-models of our model are, in order of appearance: 1. the model of the beta distribution’s mean (read, “predict <code>Rating</code>’s mean from <code>group</code>”). Then, 2. the model of <code>phi</code>; the beta distribution’s precision. 3. <code>zoi</code> is the zero-one inflation (<span class="math inline">\(\alpha\)</span>); that is, we model the probability of a binary rating as a function of <code>group</code>. 4. <code>coi</code> is the conditional one-inflation: Given that a response was {0, 1}, the probability of it being 1 is modelled on <code>group</code>.</p>
<p>As is usual in R’s formula syntax, the intercepts of each of these formulas are implicitly included. (To make intercepts explicit, use e.g. <code>Rating ~ 1 + group</code>.) Therefore, this model will have 8 parameters; the intercepts are Group A’s mean, <code>phi</code>, <code>zoi</code>, and <code>coi</code>. Then, there will be a Group B parameter for each of them, indicating the extent to which the parameters differ for Group B versus Group A.</p>
<p>If <code>group</code> has a positive effect on (the mean of) <code>Rating</code>, we may conclude that the continuous rating’s mean differs as function of Group. On the other hand, if <code>coi</code> is affected by <code>group</code>, Group has an effect on the binary {0, 1} ratings. If group has no effects on any of the parameters, we throw up our hands and design a new study.</p>
<p>Finally, we specified <code>family = zero_one_inflated_beta()</code>. Just like logistic regression, ZOIB regression is a type of generalized linear model. Therefore, each distributional parameter is modeled through a link function. The mean, zoi, and coi parameters are modeled through a logit link function. Phi is modeled through a log link function. These link functions can be changed by giving named arguments to <code>zero_one_inflated_beta()</code>. It is important to keep in mind the specific link functions, we will need them when interpreting the model’s parameters.</p>
<p>To estimate this model, we pass the resulting <code>zoib_model</code> to <code>brm()</code>, with a data frame from the current R environment, 4 CPU cores for speed, and a file argument to save the resulting model to disk. The last two arguments are optional.</p>
<pre class="r"><code>fit &lt;- brm(
  formula = zoib_model,
  data = dat,
  cores = 4,
  file = here::here(&quot;static/data/zoib-ex&quot;)
)</code></pre>
<p>brms estimates the regression model using bayesian methods: It will return random draws from the parameters’ posterior distribution. It takes less than a minute to draw samples from this model. Let’s then interpret the estimated parameters (i.e. the numerical summaries of the posterior distribution):</p>
<pre class="r"><code>summary(fit)
##  Family: zero_one_inflated_beta 
##   Links: mu = logit; phi = log; zoi = logit; coi = logit 
## Formula: Rating ~ group 
##          phi ~ group
##          zoi ~ group
##          coi ~ group
##    Data: dat (Number of observations: 100) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept         0.33      0.16     0.03     0.64       6866 1.00
## phi_Intercept     1.49      0.24     1.00     1.95       5642 1.00
## zoi_Intercept    -0.80      0.32    -1.46    -0.19       6645 1.00
## coi_Intercept     0.61      0.58    -0.48     1.77       6354 1.00
## groupB            0.92      0.21     0.50     1.31       6389 1.00
## phi_groupB        0.50      0.34    -0.17     1.16       6486 1.00
## zoi_groupB        0.08      0.44    -0.78     0.96       6994 1.00
## coi_groupB       -0.85      0.76    -2.32     0.63       6545 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>First, the summary of this model prints a paragraph of information about the model, such as the outcome family (ZOIB), link functions, etc. The regression coefficients are found under the “Population-Level Effects:” header. The columns of this section are “Estimate”, the posterior mean or point estimate of the parameter. “Est.Error”, the posterior standard deviation, or so called standard error of the parameter. Then, the lower and upper limit of the 95% Credible Interval. The two last columns are diagnostics of the model fitting procedure.</p>
<p>The first four rows of this describe the parameters for the baseline group (Group A). <code>Intercept</code> is the logit-transformed mean of the beta distribution for Group A’s ratings (the subset of ratings that were (0, 1)). To convert it back to the data scale, we’ll use the inverse link function, which for the logit is <code>plogis()</code></p>
<pre class="r"><code>plogis(0.33) %&gt;% round(3)
## [1] 0.582</code></pre>
<p>This number is the estimated mean of the beta distribution fitted to Group A’s (0, 1) rating scale responses. Next, <code>phi_Intercept</code> describes the precision of the beta distribution fitted to Group A’s slider responses, on the scale of the (log) link function. Therefore, we can convert it back to the original scale by exponentiating:</p>
<pre class="r"><code>exp(1.49) %&gt;% round(3)
## [1] 4.437</code></pre>
<p><code>zoi_Intercept</code> is the zero or one inflation of Group A’s data, on the logit scale. To convert it to a probability, we can again use the inverse of the link function:</p>
<pre class="r"><code>plogis(-0.80) %&gt;% round(3)
## [1] 0.31</code></pre>
<p>To make this concrete, we should be able to compare this number to the observed proportion of 0/1 values in the data:</p>
<pre class="r"><code>mean(dat$Rating[dat$group==&quot;A&quot;] %in% 0:1) %&gt;% round(3)
## [1] 0.311</code></pre>
<p>Above we calculated the proportion of zeros and ones in the data set, and found that it matches the estimated value of <code>zoi_Intercept</code>: <code>zoi_Intercept</code> is the estimated (logit) proportion of zeros or ones in group A’s data.</p>
<p><code>coi_Intercept</code> is the conditional one inflation; out of the 0 or 1 ratings in Group A’s data, what proportion are ones?</p>
<pre class="r"><code>plogis(0.61) %&gt;% round(3)
## [1] 0.648
# Compare to a simple count from data (sorry for ugly code)
mean(dat$Rating[dat$group==&quot;A&quot; &amp; dat$Rating %in% 0:1] == 1) %&gt;% 
  round(3)
## [1] 0.643</code></pre>
<p>The following four parameters are the effects of being in group B on these parameters. Most importantly, <code>groupB</code> is the effect of group B (versus group A) on the mean of the ratings’ assumed beta distribution, in the logit scale. Immediately, we can see that the parameter’s 95% Credible Interval does not include zero. Traditionally, this parameter would be called “significant”; group B’s (0, 1) ratings are on average greater than group A’s.</p>
<p>To transform this effect back to the data scale, we can again use <code>plogis()</code>. However, it is important to keep in mind that the effect’s size on the original scale depends on the intercept, getting smaller as the intercept increases (just like in any other generalized linear model.) The following bit of code transforms this effect and its uncertainty back to the original scale.</p>
<pre class="r"><code>h &lt;- c(&quot;B - A&quot; = &quot;plogis(Intercept + groupB) = plogis(Intercept)&quot;)
hypothesis(fit, h)
## Hypothesis Tests for class b:
##   Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star
## 1      B - A     0.19      0.05     0.11     0.28         NA        NA    *
## ---
## &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI.
## Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
<p>The data were simulated with the <code>rzoib()</code> function, and I set <span class="math inline">\(\alpha = 0.25, \gamma = 0.5, \mu = 0.6 + 0.15\mbox{groupB}, \phi = 5\)</span>. Therefore, the results of the t-tests and nonparametric tests were misses; a true effect was missed. On the other hand, the ZOIB regression model detected the true effect of group on the beta distribution’s mean.</p>
<p>Finally, let’s visualize this key finding using the <code>marginal_effects()</code> function from brms.</p>
<pre class="r"><code>plot(
  marginal_effects(fit, dpar = &quot;mu&quot;), 
  points = TRUE, 
  point_args = list(width = .05, shape = 1)
)</code></pre>
<div class="figure"><span id="fig:ex-me"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/ex-me-1.png" alt="Estimated mu parameters from the example ZOIB fit, as filled points and error bars (95\% CIs), with the original data (empty circles)." width="672" />
<p class="caption">
Figure 8: Estimated mu parameters from the example ZOIB fit, as filled points and error bars (95% CIs), with the original data (empty circles).
</p>
</div>
<p>Comparing Figure <a href="#fig:ex-me">8</a> to Figure <a href="#fig:zoib-example">7</a> reveals the fundamental difference of the normal t-test model, and the ZOIB model: The ZOIB regression (<a href="#fig:ex-me">8</a>) has found a large difference between the continuous part of the slider ratings’ means because it has treated the data with an appropriate model. By conflating the continuous and binary data, the t-test did not detect this difference.</p>
<p>In conclusion, this example showed that ZOIB results in more informative, and potentially more accurate, inferences from analog scale (“slider”) data. Of course, in this simulation we had the benefit of knowing the true state of matters: The data were simulated from a ZOIB model. Nevertheless, we have reasoned that by respecting the major features of slider scale data, the ZOIB is a more accurate representation of it, and was therefore able to detect a difference where the t-test did not. Next, I put this conjecture to a test by conducting a small simulation study.</p>
</div>
</div>
<div id="simulation-compare-zoib-and-t-test-performances" class="section level1">
<h1>Simulation: Compare ZOIB and t-test performances</h1>
<p>To compare the performance of the t-test and ZOIB in a little bit more detail, I conducted a small simulation study. I simulated 100 data sets of 200 ratings from two independent groups, from the ZOIB model (100 ratings per group). I set <span class="math inline">\(\alpha = 0.2, \gamma = 0.7, \mu = 0.6 + 0.1\mbox{groupB}, \phi = 5\)</span>; that is, there was a small effect of group on the mean of the beta distribution, and all other parameters were constant across groups. A sample of the resulting data sets is shown in Figure <a href="#fig:sim-examplesets">9</a></p>
<div class="figure"><span id="fig:sim-examplesets"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/sim-examplesets-1.png" alt="Six randomly selected simulated data sets. Points are individual ratings (jittered to show overlapping points), while blue symbols indicate the means and bootstrapped 95\% CIs." width="672" />
<p class="caption">
Figure 9: Six randomly selected simulated data sets. Points are individual ratings (jittered to show overlapping points), while blue symbols indicate the means and bootstrapped 95% CIs.
</p>
</div>
<p>I first conducted an independent samples, unequal variances t-test on each of the 100 simulated data sets, comparing the two groups’ mean ratings. 35% of these t-tests were significantly positive at the .05 level. That is, the power of the t-test in this simulation was about 35%. (Uncertainty in this value is moderate, because I only did 100 simulation runs.)</p>
<p>I then estimated the ZOIB model for each of the 100 simulated data sets. Statistical significance does not play a role in Bayesian statistics, but to most easily compare the results of these two models, I calculated the proportion of simulations for which the estimated Group on <span class="math inline">\(\mu\)</span> effect’s 95% Credible Interval was entirely above zero. If a 95% CI does not include zero, disrespecting the philosophical differences of bayesian and frequentist statistics, I may say that the estimate is “significant”.</p>
<p>This parameter was significantly greater than zero in 67% of the ZOIB models estimated on the same 100 simulated data sets. That is, the power of this model to detect an effect was much greater than the power of the t-test. These results are illustrated in Figure <a href="#fig:sims-compare">10</a>.</p>
<div class="figure"><span id="fig:sims-compare"></span>
<img src="/post/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models_files/figure-html/sims-compare-1.png" alt="Results of the simulation study. Top: the estimated mean difference and 95\% CI of the two groups' ratings, as estimated by a t-test. Red = not statistically significant; blue = statistically significant. The data sets are ordered on the x axis on the estimated mean difference. Bottom: simulation results of the ZOIB model. Same as the top panel, but the estimated parameter is the difference between the two group's mu parameters of the beta distribution. (I back-transformed the mu parameter from the logit scale to the data scale to make the results numerically more comparable across the t-test and ZOIB models.) In both panels, the horizontal green line indicates the true effect used in the simulations." width="672" />
<p class="caption">
Figure 10: Results of the simulation study. Top: the estimated mean difference and 95% CI of the two groups’ ratings, as estimated by a t-test. Red = not statistically significant; blue = statistically significant. The data sets are ordered on the x axis on the estimated mean difference. Bottom: simulation results of the ZOIB model. Same as the top panel, but the estimated parameter is the difference between the two group’s mu parameters of the beta distribution. (I back-transformed the mu parameter from the logit scale to the data scale to make the results numerically more comparable across the t-test and ZOIB models.) In both panels, the horizontal green line indicates the true effect used in the simulations.
</p>
</div>
<p>As can be seen in this figure, in this particular setup, the t-tests severely underperformed in detecting a true effect when compared to the ZOIB model. Of course, this is to be expected, because the data were generated from the ZOIB model.</p>
<p>Out there in the wild, which of these models is closer to the true data generating process for slider scale ratings? Normal models, or ZOIB? (Or, most likely, some other class of models?) As we have seen, normal models may be poor representations of bounded and skewed slider scale data. It is therefore possible that the routine use of normal models in analyzing slider scale data can result in missing true effects at a rate higher than indicated by conventional power analyses.</p>
</div>
<div id="discussion" class="section level1">
<h1>Discussion</h1>
<p>I have not extensively reviewed the performance of the ZOIB model in this blog post. Neither did I analyze real slider scale data. Therefore, I can not and would not recommend exclusively favoring the ZOIB model over normal models for the analysis of slider scale data. However, I can recommend at least trying ZOIB for your own slider scale data, and thinking about what models might best fit your data if they appear non normal.</p>
<div id="limitations" class="section level2">
<h2>Limitations</h2>
<p>There are many limitations to the current discussion, and the simulation studies should be considerably expanded to more realistic and variable situations.</p>
<p>One limitation of the ZOIB model might be what I here discussed as its main benefit. ZOIB separates the binary and continuous processes, such that a predictor’s effect on one or both of them are independent in the model. However, it is likely that these two processes are somehow correlated. Thus, ZOIB does not give only one “effect” of a predictor on the ratings, but two, one for the continuous part, and one for the binary. By not getting a single effect, if nothing else, the model is more complex and probably more difficult to analyze and/or explain.</p>
</div>
<div id="further-reading" class="section level2">
<h2>Further reading</h2>
<p>The beta regression model has previously been discussed as a reasonable model of data in the open (0, 1) interval <span class="citation">(Ferrari and Cribari-Neto 2004)</span>. It’s application in psychological studies has also been discussed by <span class="citation">Smithson and Verkuilen (2006; see also Verkuilen and Smithson 2012)</span>. These earlier papers recommended that values at the 0 and 1 boundaries be somehow transformed to make the data suitable for the model, but transforming the data such that a model can be fitted seems like a bad idea.</p>
<p>Mixtures of beta and discrete models were discussed by <span class="citation">Ospina and Ferrari (2008)</span>, and an R package for estimation of the ZOIB model was introduced by <span class="citation">Liu and Kong (2015)</span>. <span class="citation">Liu and Eugenio (2018)</span> found that ZOIB models are better estimated with Bayesian methods than with maximum likelihood methods.</p>
<p>More information about the brms package can be found in <span class="citation">Bürkner (2017)</span>, and in the excellent vignettes at <a href="https://cran.rstudio.com/web/packages/brms/" class="uri">https://cran.rstudio.com/web/packages/brms/</a>.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-BurknerbrmsPackageBayesian2017">
<p>Bürkner, Paul-Christian. 2017. “Brms: An R Package for Bayesian Multilevel Models Using Stan.” <em>Journal of Statistical Software</em> 80 (1): 1–28. <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a>.</p>
</div>
<div id="ref-BurknerOrdinalRegressionModels2018">
<p>Bürkner, Paul-Christian, and Matti Vuorre. 2018. “Ordinal Regression Models in Psychology: A Tutorial.” <em>PsyArXiv</em>, February. <a href="https://doi.org/10.31234/osf.io/x8swp">https://doi.org/10.31234/osf.io/x8swp</a>.</p>
</div>
<div id="ref-FerrariBetaRegressionModelling2004">
<p>Ferrari, Silvia, and Francisco Cribari-Neto. 2004. “Beta Regression for Modelling Rates and Proportions.” <em>Journal of Applied Statistics</em> 31 (7): 799–815. <a href="https://doi.org/10.1080/0266476042000214501">https://doi.org/10.1080/0266476042000214501</a>.</p>
</div>
<div id="ref-LiddellAnalyzingordinaldata2018">
<p>Liddell, Torrin M., and John K. Kruschke. 2018. “Analyzing Ordinal Data with Metric Models: What Could Possibly Go Wrong?” <em>Journal of Experimental Social Psychology</em> 79 (November): 328–48. <a href="https://doi.org/10.1016/j.jesp.2018.08.009">https://doi.org/10.1016/j.jesp.2018.08.009</a>.</p>
</div>
<div id="ref-LiureviewcomparisonBayesian2018">
<p>Liu, Fang, and Evercita C Eugenio. 2018. “A Review and Comparison of Bayesian and Likelihood-Based Inferences in Beta Regression and Zero-or-One-Inflated Beta Regression.” <em>Statistical Methods in Medical Research</em> 27 (4): 1024–44. <a href="https://doi.org/10.1177/0962280216650699">https://doi.org/10.1177/0962280216650699</a>.</p>
</div>
<div id="ref-LiuzoibPackageBayesian2015">
<p>Liu, Fang, and Yunchuan Kong. 2015. “Zoib: An R Package for Bayesian Inference for Beta Regression and Zero/One Inflated Beta Regression.” <em>The R Journal</em> 7 (2): 34–51.</p>
</div>
<div id="ref-OspinaInflatedbetadistributions2008">
<p>Ospina, Raydonal, and Silvia L. P. Ferrari. 2008. “Inflated Beta Distributions.” <em>Statistical Papers</em> 51 (1): 111. <a href="https://doi.org/10.1007/s00362-008-0125-4">https://doi.org/10.1007/s00362-008-0125-4</a>.</p>
</div>
<div id="ref-Smithsonbetterlemonsqueezer2006">
<p>Smithson, Michael, and Jay Verkuilen. 2006. “A Better Lemon Squeezer? Maximum-Likelihood Regression with Beta-Distributed Dependent Variables.” <em>Psychological Methods</em> 11 (1): 54–71. <a href="https://doi.org/10.1037/1082-989X.11.1.54">https://doi.org/10.1037/1082-989X.11.1.54</a>.</p>
</div>
<div id="ref-VerkuilenMixedMixtureRegression2012">
<p>Verkuilen, Jay, and Michael Smithson. 2012. “Mixed and Mixture Regression Models for Continuous Bounded Responses Using the Beta Distribution.” <em>Journal of Educational and Behavioral Statistics</em> 37 (1): 82–113. <a href="https://doi.org/10.3102/1076998610396895">https://doi.org/10.3102/1076998610396895</a>.</p>
</div>
<div id="ref-YarkoniChoosingPredictionExplanation2017">
<p>Yarkoni, Tal, and Jacob Westfall. 2017. “Choosing Prediction over Explanation in Psychology: Lessons from Machine Learning.” <em>Perspectives on Psychological Science</em> 12 (6): 1100–1122. <a href="https://doi.org/10.1177/1745691617693393">https://doi.org/10.1177/1745691617693393</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Technically, normal models assume that the residuals are normally distributed. I will keep referring to data being normally distributed or not, for clarity.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
